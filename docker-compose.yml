version: '3.9'
services:
  nifi:
    build:
      context: docker_templates/nifi
    container_name: nifi
    environment:
    - NIFI_WEB_HTTPS_PORT=8443
    - SINGLE_USER_CREDENTIALS_USERNAME=admin
    - SINGLE_USER_CREDENTIALS_PASSWORD=ctsBtRBKHRAx69EqUghvvgEvjnaLjFEB
    - NIFI_HOME=/opt/nifi/nifi-current
    - NIFI_LOG_DIR=/opt/nifi/nifi-current/logs
    - NIFI_TOOLKIT_HOME=/opt/nifi/nifi-toolkit-current
    - NIFI_PID_DIR=/opt/nifi/nifi-current/run
    - NIFI_BASE_DIR=/opt/nifi
    ports:
    - 8443:8443
    - 52020:52020
    networks:
    - data_pipeline_network
    healthcheck:
      test:
      - CMD
      - 'true'
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    environment:
      CLUSTER_NAME: ${HADOOP_CLUSTER_NAME}
      CORE_CONF_fs_defaultFS: hdfs://namenode:8020
    volumes:
    - hadoopstandalone_namenode_namenode_data:/hadoop/dfs/name
    ports:
    - 9870:9870
    - 8020:8020
    networks:
    - data_pipeline_network
    healthcheck:
      test:
      - CMD
      - curl
      - --fail
      - http://localhost:9870/
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    environment:
      CORE_CONF_fs_defaultFS: hdfs://namenode:8020
    volumes:
    - hadoopstandalone_datanode_datanode_data:/hadoop/dfs/data
    networks:
    - data_pipeline_network
    depends_on:
      namenode:
        condition: service_healthy
    restart: always
    healthcheck:
      test:
      - CMD
      - curl
      - --fail
      - http://localhost:9864/
      interval: 30s
      timeout: 10s
      retries: 3
  prefect-orion:
    image: prefecthq/prefect:2-latest
    container_name: prefect-orion
    command: "bash -c \"\n  prefect server start --host 0.0.0.0 --port 4200\n\"\n"
    ports:
    - 4200:4200
    volumes:
    - prefect_prefect-orion_prefect_data:/root/.prefect
    networks:
    - data_pipeline_network
    healthcheck:
      test:
      - CMD
      - python3
      - -c
      - import http.client; conn = http.client.HTTPConnection('localhost', 4200);
        conn.request('GET', '/health'); exit(0) if conn.getresponse().status == 200
        else exit(1)
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
  prefect-worker:
    image: prefecthq/prefect:2-latest
    container_name: prefect-worker
    depends_on:
      prefect-orion:
        condition: service_healthy
    environment:
      PREFECT_API_URL: http://prefect-orion:4200/api
    command: "bash -c \"\n  prefect worker start -p default\n\"\n"
    healthcheck:
      test:
      - CMD
      - python3
      - -c
      - import http.client, json; conn = http.client.HTTPConnection('prefect-orion',
        4200); conn.request('GET', '/api/health'); resp = conn.getresponse(); exit(0)
        if resp.status == 200 else exit(1)
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks:
    - data_pipeline_network
    restart: always
networks:
  data_pipeline_network: {}
volumes:
  hadoopstandalone_namenode_namenode_data: {}
  hadoopstandalone_datanode_datanode_data: {}
  prefect_prefect-orion_prefect_data: {}
