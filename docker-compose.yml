version: '3.9'
services:
  zoo1:
    image: confluentinc/cp-zookeeper:7.3.2
    hostname: zoo1
    container_name: zoo1
    ports:
    - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_CLIENT_PORT}
      ZOOKEEPER_SERVER_ID: ${ZOOKEEPER_SERVER_ID}
      ZOOKEEPER_SERVERS: ${ZOOKEEPER_SERVERS}
    networks:
    - data_pipeline_network
  kafka1:
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka1
    container_name: kafka1
    ports:
    - 9092:9092
    - 29092:29092
    - 9999:9999
    environment:
      KAFKA_ADVERTISED_LISTENERS: ${KAFKA_ADVERTISED_LISTENERS}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: ${KAFKA_LISTENER_SECURITY_PROTOCOL_MAP}
      KAFKA_INTER_BROKER_LISTENER_NAME: ${KAFKA_INTER_BROKER_LISTENER_NAME}
      KAFKA_ZOOKEEPER_CONNECT: ${KAFKA_ZOOKEEPER_CONNECT}
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID}
      KAFKA_LOG4J_LOGGERS: ${KAFKA_LOG4J_LOGGERS}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR}
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR}
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: ${KAFKA_TRANSACTION_STATE_LOG_MIN_ISR}
      KAFKA_JMX_PORT: ${KAFKA_JMX_PORT}
      KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
      KAFKA_AUTHORIZER_CLASS_NAME: ${KAFKA_AUTHORIZER_CLASS_NAME}
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: ${KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND}
    depends_on:
      zoo1:
        condition: service_started
    restart: always
    networks:
    - data_pipeline_network
  kafka-schema-registry:
    image: confluentinc/cp-schema-registry:7.3.2
    hostname: kafka-schema-registry
    container_name: kafka-schema-registry
    ports:
    - 8081:8081
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: ${SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS}
      SCHEMA_REGISTRY_HOST_NAME: ${SCHEMA_REGISTRY_HOST_NAME}
      SCHEMA_REGISTRY_LISTENERS: ${SCHEMA_REGISTRY_LISTENERS}
    depends_on:
      zoo1:
        condition: service_started
      kafka1:
        condition: service_started
    restart: always
    networks:
    - data_pipeline_network
  kafka-rest-proxy:
    image: confluentinc/cp-kafka-rest:7.3.2
    hostname: kafka-rest-proxy
    container_name: kafka-rest-proxy
    ports:
    - 8082:8082
    environment:
      KAFKA_REST_LISTENERS: ${KAFKA_REST_LISTENERS}
      KAFKA_REST_SCHEMA_REGISTRY_URL: ${KAFKA_REST_SCHEMA_REGISTRY_URL}
      KAFKA_REST_HOST_NAME: ${KAFKA_REST_HOST_NAME}
      KAFKA_REST_BOOTSTRAP_SERVERS: ${KAFKA_REST_BOOTSTRAP_SERVERS}
    depends_on:
      zoo1:
        condition: service_started
      kafka1:
        condition: service_started
      kafka-schema-registry:
        condition: service_started
    restart: always
    networks:
    - data_pipeline_network
  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.3.2
    hostname: kafka-connect
    container_name: kafka-connect
    ports:
    - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: ${CONNECT_BOOTSTRAP_SERVERS}
      CONNECT_REST_PORT: ${CONNECT_REST_PORT}
      CONNECT_GROUP_ID: ${CONNECT_GROUP_ID}
      CONNECT_CONFIG_STORAGE_TOPIC: ${CONNECT_CONFIG_STORAGE_TOPIC}
      CONNECT_OFFSET_STORAGE_TOPIC: ${CONNECT_OFFSET_STORAGE_TOPIC}
      CONNECT_STATUS_STORAGE_TOPIC: ${CONNECT_STATUS_STORAGE_TOPIC}
      CONNECT_KEY_CONVERTER: ${CONNECT_KEY_CONVERTER}
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: ${CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL}
      CONNECT_VALUE_CONVERTER: ${CONNECT_VALUE_CONVERTER}
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: ${CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL}
      CONNECT_INTERNAL_KEY_CONVERTER: ${CONNECT_INTERNAL_KEY_CONVERTER}
      CONNECT_INTERNAL_VALUE_CONVERTER: ${CONNECT_INTERNAL_VALUE_CONVERTER}
      CONNECT_REST_ADVERTISED_HOST_NAME: ${CONNECT_REST_ADVERTISED_HOST_NAME}
      CONNECT_LOG4J_ROOT_LOGLEVEL: ${CONNECT_LOG4J_ROOT_LOGLEVEL}
      CONNECT_LOG4J_LOGGERS: ${CONNECT_LOG4J_LOGGERS}
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: ${CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR}
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: ${CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR}
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: ${CONNECT_STATUS_STORAGE_REPLICATION_FACTOR}
      CONNECT_PLUGIN_PATH: ${CONNECT_PLUGIN_PATH}
    volumes:
    - C:\Users\AHMAD.SHAHEER\Desktop\Capstone\temp_merged_volumes\apachekafka_kafka-connect_connectors:/etc/kafka-connect/jars/
    depends_on:
      zoo1:
        condition: service_started
      kafka1:
        condition: service_started
      kafka-schema-registry:
        condition: service_started
      kafka-rest-proxy:
        condition: service_started
    restart: always
    networks:
    - data_pipeline_network
  conduktorDB:
    image: postgres:14
    hostname: conduktorDB
    container_name: conduktorDB
    volumes:
    - apachekafka_conduktorDB_pg_data:/var/lib/postgresql/data
    ports:
    - 5432:5432
    environment:
      POSTGRES_DB: ${CONDUKTOR_POSTGRES_DB}
      POSTGRES_USER: ${CONDUKTOR_POSTGRES_USER}
      POSTGRES_PASSWORD: ${CONDUKTOR_POSTGRES_PASSWORD}
      POSTGRES_HOST_AUTH_METHOD: ${CONDUKTOR_POSTGRES_HOST_AUTH_METHOD}
    healthcheck:
      test:
      - CMD-SHELL
      - pg_isready -U conduktor -d conduktor-console -h localhost
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    networks:
    - data_pipeline_network
  conduktor-console:
    image: conduktor/conduktor-console:1.26.0
    hostname: conduktor-console
    container_name: conduktor-console
    ports:
    - 8080:8080
    volumes:
    - apachekafka_conduktor-console_conduktor_data:/var/conduktor
    environment:
      CDK_DATABASE_URL: ${CDK_DATABASE_URL}
      CDK_CLUSTERS_0_ID: ${CDK_CLUSTERS_0_ID}
      CDK_CLUSTERS_0_NAME: ${CDK_CLUSTERS_0_NAME}
      CDK_CLUSTERS_0_COLOR: ${CDK_CLUSTERS_0_COLOR}
      CDK_CLUSTERS_0_BOOTSTRAPSERVERS: ${CDK_CLUSTERS_0_BOOTSTRAPSERVERS}
      CDK_CLUSTERS_0_SCHEMAREGISTRY_URL: ${CDK_CLUSTERS_0_SCHEMAREGISTRY_URL}
      CDK_CLUSTERS_0_KAFKACONNECTS_0_URL: ${CDK_CLUSTERS_0_KAFKACONNECTS_0_URL}
      CDK_CLUSTERS_0_KAFKACONNECTS_0_NAME: ${CDK_CLUSTERS_0_KAFKACONNECTS_0_NAME}
    depends_on:
      conduktorDB:
        condition: service_healthy
      kafka1:
        condition: service_started
    restart: always
    networks:
    - data_pipeline_network
  postgres:
    image: postgres:14
    environment:
      POSTGRES_USER: ${POSTGRES_USER_PG}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD_PG}
      POSTGRES_DB: ${POSTGRES_DB_PG}
    ports:
    - 5433:5432
    volumes:
    - postgres_postgres_postgres_data:/var/lib/postgresql/data
    networks:
    - data_pipeline_network
  pgadmin:
    image: dpage/pgadmin4:latest
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
    ports:
    - 5050:80
    networks:
    - data_pipeline_network
    restart: always
  jobmanager:
    image: apache/flink:1.16.0
    container_name: flink-jobmanager
    command: jobmanager
    environment:
    - JOB_MANAGER_RPC_ADDRESS=${FLINK_JOB_MANAGER_RPC_ADDRESS}
    - 'FLINK_PROPERTIES=

      jobmanager.rpc.address: ${FLINK_JOB_MANAGER_RPC_ADDRESS}

      '
    ports:
    - 8084:8081
    networks:
    - data_pipeline_network
    volumes:
    - apacheflink_jobmanager_jobmanager-logs:/opt/flink/log
  taskmanager:
    image: apache/flink:1.16.0
    container_name: flink-taskmanager
    command: taskmanager
    environment:
    - JOB_MANAGER_RPC_ADDRESS=${FLINK_JOB_MANAGER_RPC_ADDRESS}
    - 'FLINK_PROPERTIES=

      jobmanager.rpc.address: ${FLINK_JOB_MANAGER_RPC_ADDRESS}

      '
    depends_on:
      jobmanager:
        condition: service_started
    restart: always
    networks:
    - data_pipeline_network
    volumes:
    - apacheflink_taskmanager_taskmanager-logs:/opt/flink/log
  airflow-db:
    image: postgres:14
    container_name: airflow-db
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
    - airflow_airflow-db_airflow_db_data:/var/lib/postgresql/data
    ports:
    - 5434:5432
    networks:
    - data_pipeline_network
  airflow-init:
    image: apache/airflow:2.6.2
    container_name: airflow-init
    depends_on:
      airflow-db:
        condition: service_started
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DB_CONN}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW_LOAD_EXAMPLES}
    command: "bash -c \"\n  echo 'Initializing Airflow DB...' &&\n  airflow db init\
      \ &&\n  echo 'Creating Airflow admin user...' &&\n  airflow users create --username\
      \ ${AIRFLOW_ADMIN_USER} --password ${AIRFLOW_ADMIN_PASS} --firstname Airflow\
      \ --lastname Admin --role Admin --email ${AIRFLOW_ADMIN_EMAIL} &&\n  echo 'Airflow\
      \ initialization is complete! Container will stay alive for healthcheck...'\
      \ &&\n  tail -f /dev/null\n\"\n"
    healthcheck:
      test:
      - CMD-SHELL
      - airflow db check
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 5s
    networks:
    - data_pipeline_network
  airflow-scheduler:
    image: apache/airflow:2.6.2
    container_name: airflow-scheduler
    depends_on:
      airflow-db:
        condition: service_started
      airflow-init:
        condition: service_healthy
    restart: always
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DB_CONN}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW_LOAD_EXAMPLES}
    volumes:
    - airflow_airflow-scheduler_airflow_dags:/opt/airflow/dags
    - airflow_airflow-scheduler_airflow_logs:/opt/airflow/logs
    command:
    - airflow
    - scheduler
    networks:
    - data_pipeline_network
  airflow-webserver:
    image: apache/airflow:2.6.2
    container_name: airflow-webserver
    depends_on:
      airflow-scheduler:
        condition: service_started
      airflow-init:
        condition: service_healthy
    restart: always
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DB_CONN}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW_LOAD_EXAMPLES}
    ports:
    - 8085:8080
    volumes:
    - airflow_airflow-webserver_airflow_dags:/opt/airflow/dags
    - airflow_airflow-webserver_airflow_logs:/opt/airflow/logs
    command:
    - airflow
    - webserver
    networks:
    - data_pipeline_network
networks:
  data_pipeline_network: {}
volumes:
  apachekafka_conduktorDB_pg_data: {}
  apachekafka_conduktor-console_conduktor_data: {}
  postgres_postgres_postgres_data: {}
  apacheflink_jobmanager_jobmanager-logs: {}
  apacheflink_taskmanager_taskmanager-logs: {}
  airflow_airflow-db_airflow_db_data: {}
  airflow_airflow-scheduler_airflow_dags: {}
  airflow_airflow-scheduler_airflow_logs: {}
  airflow_airflow-webserver_airflow_dags: {}
  airflow_airflow-webserver_airflow_logs: {}
